Official Google Cloud Certified Associate Cloud Engineer Study Guide
====================================================================

GCP Products Decision Tree
--------------------------

**GCP Network Tier decision tree**

image::https://miro.medium.com/max/1200/1*JnDFATWt5-7DgQusex4BeQ.png[GCP Network Tier decision tree]

**GCP Network Service Tiers decision tree**

image::Associate Cloud Engineer Study Guide - Network Service Tiers.jpeg[GCP Network Service Tiers decision tree]

**GCP Authentiation options decision tree**

image::https://miro.medium.com/max/1200/1*Uw6w0_X8X29jhpfMgW58Sw.png[GCP Authentiation options decision tree]

**GCP Compute options decision tree**

image::https://miro.medium.com/max/628/1*OV12s1M9O3OcEn2cwdtmEA.png[GCP Compute options decision tree]

**Google Data products decision tree**

image::Google Data products decision tree.png[Google Data products decision tree]

**Google Cloud Dataflow vs. Cloud Dataproc**

image::https://cloud.google.com/dataflow/images/flow-vs-proc-flowchart.svg[Google Dataflow vs. Dataproc]

**Data encryption decision tree**

image::https://miro.medium.com/max/640/1*LTWOlTPPGXIWSPmJEoBVRQ.png[Data encryption decision tree]


Assessment Test
---------------

- Machine type, boot disk image or container image, zone, and labels are all configuration parameters or attributes of a VM
- **gsutil mb** is the specific command for creating, or making, a bucket
- Create a lifecycle management configuration policy specifying an age of 90 days and SetStorageClass as nearline is the most efficient way to meet object management policy requirement. Read more: Storage classes https://cloud.google.com/storage/docs/storage-classes, Object Lifecycle Management https://cloud.google.com/storage/docs/lifecycle
- **gsutil rsync** to synchronize the contents of the two buckets
- VPCs are **Global** resources. Google operates a global network, and VPCs are resources that can span that global network
- **gcloud** by default will retry a failed network operation and will wait a long time before each retry. The time to wait is calculated using a truncated binary exponential back-off strategy
- Only Google Spanner and Cloud SQL databases support transactions and have a SQL interface. Datastore has transactions but does not support fully compliant SQL; it has a SQL-like query language. Cloud Storage does not support transactions or SQL
- App Engine is a PaaS that allows developers to deploy full applications without having to manage servers or clusters. Compute Engine and Kubernetes Engine require management of servers. Cloud Functions is suitable for short-running but not full applications
- BigQuery is designed for petabyte-scale analytics and provides a SQL interface
- Cloud Dataflow allows for stream and batch processing of data and is well suited for this kind of ETL work. Dataproc is a managed Hadoop and Spark service that is used for big data analytics
- Preemptible virtual machines may be shut down at any time but will always be shut down after running 24 hours by Google
- **Organizations, folders, and projects** are the components used to manage an organizational hierarchy. **Buckets, directories, and subdirectories** are used to organize storage
- Cloud Dataproc is the managed Spark service. Cloud Dataflow is for stream and batch processing of data, BigQuery is for analytics

**Google Cloud Function**

image::Associate Cloud Engineer Study Guide - Cloud Function.png[Google Cloud Function]


Chapter 1 - Overview of Google Cloud Platform
---------------------------------------------

- Object storage, like Cloud Storage, provides redundantly stored objects without limits on the amount of data you can store
- Block sizes in a block storage system can vary. Block size is established when a file system is created
- Firewalls are software-defined network controls that limit the flow of traffic into and out of a network or subnetwork. Routers are used to move traffic to appropriate destinations on the network. Identity access management is used for authenticating and authorizing users
- Specialized services in GCP are serverless
- Investing in servers should be based on demand for server capacity
- The characteristics of the server, such as the number of virtual servers, the amount of memory, and the region where you run the VM, influence the cost
- Containers give the most flexibility for using the resources of a cluster efficiently and orchestration platforms reduce the operations overhead
- Cloud Filestore is based on Network Filesystem (NSF), which is a distributed file management system
- When you create a network, it is treated as a virtual private cloud. Resources are added to the VPC and are not accessible outside the VPC unless
you explicitly configure them to be
- Caches use memory, and that makes them the fastest storage type for reading data. Caches are data stores on the backend of distributed systems, not the clients. Caches can get out of sync with the system of truth because the system of truth could be updated, but the cache may not be updated
- Cloud providers have large capacity and can quickly allocate those resources to different customers. With a mix of customers and workloads, they can optimize the allocation of resources
- Specialized services are monitored by Google so users do not have to monitor them. Specialized services provide a specific compute functionality but do not require the user to configure any resources. They also provide APIs
- Attached drives are block storage devices. Cloud Storage is the object storage service and does not attach directly to a VM
- Databases require persistent storage on block devices. Object storage does not provide data block or file system storage


Chapter 2 - Google Cloud Computing Services
-------------------------------------------

GCP services list:

- Computing resources - Compute Engine, Kubernetes / Containers Engine, App Engine (standard / flexible environment), Cloud Functions (event-driven processing, short-running code)
- Storage resources - Cloud Storage (for object storage, single unit of data and multiple regions), Persistent Disk (block storage), Cloud Storage for Firebase, Cloud Filestore (shared file system, NFS easily to mount)
- Databases - Cloud SQL (managed relational database without having to attend to database administration tasks, such as backing up databases or patching database software), Cloud Spanner (globally distributed relational database, with the ability to scale horizontally, supports ANSI 2011 standard SQL), Cloud Bigtable (NoSQL as wide-column data model, low-latency write and read operations, support millions of operations per second, Hbase API), Cloud Datastore (NoSQL document database, collection of key-value pair, flexible schemas, REST API, shard or partition, supports transactions, indexes, and SQL-like queries), Cloud Memorystore (in-memory cache service, managed Redis service), Cloud Firestore (NoSQL database service designed as a backend for highly scalable web and mobile applications, includes a Datastore mode, which enables applications written for Datastore to work with Cloud Firebase)
- Networking services - Virtual Private Cloud (can span the globe without relying on the public Internet), Cloud Load Balancing (distribute the workload within and across regions, adapt to failed or degraded servers, and autoscale your compute resources to accommodate changes in workload), Cloud Armor, Cloud CDN, Cloud Interconnect (interconnects and peering), Cloud DNS (automatically scale)
- Identity management and security (users, roles, and privileges, groups of related permissions can be bundled into roles)
- Development tools - Cloud SDK
- Management tools - Stackdriver, Monitoring, Logging, Error Reporting, Trace, Debugger, Profiler
- Specialized services - Apigee API Platform, Data Anylytics (BigQuery, Cloud Dataflow, Dataproc, Dataprep), AI and Machine Learning (Cloud AutoML, Machine Learning Engine, NLP, Vision)

- Container is another approach to isolating computing resources is to use features of the host operating system to isolate processes and resources without hypervisor. No guest operating systems run on top of the container manager. Containers make use of host operating system functionality, while the operating system and container manager ensure isolation between the running containers
- App Engine is well suited for web and mobile backend applications
- A zone is considered a single failure domain
- Load balancers can route workload based on network-level or application-level rules. GCP load balancers can distribute workloads globally
- Why Çloud, enable customers to focus on application development while the cloud provider takes on more responsibility for maintaining the underlying compute infrastructure
- App Engine flexible environments allow you to run containers on the App Engine PaaS
- Cloud CDN acts as a first line of defense in the case of DDoS attacks
- Stackdriver Logging is used to consolidate and manage logs generated by applications and servers
- Cloud SQL does not have global transaction
- Dataproc is designed to execute workflows in both batch and streaming modes
- Error reporting consolidates crash information


Chapter 3 - Projects, Service, Accounts, and Billing
----------------------------------------------------

- All resources are organized within your **resource hierarchy** (Organisation, Folder, Project). Organization policies are defined in terms of constraints on resources in the **resource hierarchy**. IAM lets you assign permissions so users or roles can perform specific operations in the cloud. The Organization Policy Service lets you specify limits on the ways resources can be used. IAM specifies who can do things, and the Organization Policy Service specifies what can be done with resources
- Projects must have billing accounts associated with them. A billing account can be associated with more than one project
- It is in projects that we create resources, use GCP services, manage permissions, and manage billing options
- Organization will have a quota of projects it can create. Google makes decisions about project quotas based on typical use, the customer’s usage history, and other factors
- To Policy Evaluation, policies are inherited and cannot be disabled or overridden by objects lower in the hierarchy
- Role (Primitive, Predefined, Custom) is a collection of permissions
- Service accounts are identities can be assigned to a resource. Resources can perform operations that the service account has permission to perform. Service accounts are treat them as resources and identities
- Billing accounts: self-serve and invoiced. A budget is associated with a billing account
- Inherited policies can be ONLY overridden by defining a policy at a folder or project level
- A self-service Billing account is appropriate only for amounts that are within the credit limits of credit cards
- When a user is granted **iam.serviceAccountUser** at the project level, that user can manage all service accounts in the project. If a new service account is created, they will automatically have privilege to manage that service account
- When a service account is created, Google generates encrypted keys for authentication
- Service accounts are resources that are managed by administrators
- Primitive roles are building blocks for other roles
- Users with the Organization IAM role are not necessarily responsible for determining what privileges should be assigned to users. That is determined based on the person’s role in the organization and the security policies established within the organization


Chapter 4 - Introduction to Computing in Google Cloud
-----------------------------------------------------

- App Engine (dynamic and resident instances). The App Engine standard environment can autoscale down to no instances when there is no load and thereby minimize costs. App Engine flexible environment is similar to the Kubernetes Engine, and flexible environment will always be **at least one container** running with your service
- High performance computing clusters can use preemptible machines because work on a preemptible machine can be automatically rescheduled for another node on the cluster when a server is preempted
- Kubernetes administrates clusters of virtual and bare-metal machines, and is designed to support clusters that run a variety of applications.
- A group containers in Kubernetes called pods. Containers within a single pod share storage, network resources, an IP address and port space. A pod is a logically single unit for providing a service. A group of running identical pods is called a deployment. The identical pods are referred to as replicas.
- Kubernetes Engine is for large-scale applications that require high availability and high reliability. Kubernetes manage services which have different lifecycles and scalability requirements as a logical unit and at levels of abstraction
- Kubernetes uses 25 percent of memory up to 4GB and then slightly less for the next 4GB, and it continues to reduce the percentage of additional memory down to 2 percent of
memory over 128GB; takes 6 percent CPU resources of the first core, down to 0.25 percent of any cores above four cores
- Kubernetes does not provide vulnerability scanning. GCP does have a Cloud Security Scanner product, but that is designed to work with App Engine to identify common application
vulnerabilities
- Cloud Functions provides the “glue” between services
- All Google regions have the same level of service level agreement, so reliability is the same
- Preemptible VM can save a snapshot and use that to create a new regular instance
- Custom machine types can have between 1 and 64 vCPUs and up to 6.5GB of memory per vCPU


Chapter 5 - Computing with Compute Engine Virtual Machines
----------------------------------------------------------

- All operations you perform will apply to resources in the selected project
- The first time you try to work a VM you will have to create a billing account. When you start using the console, create a project, only if billing is enabled
- A zone is a data center–like facility within a region. Different zones may have different machine types available, so you will need to specify a region first and then a zone to determine the set of machine types available
- The boot disk type, which can be either Standard Persistent Disk or SSD Persistent Disk
- Labels and a general description will help track numbers of VMs and their related costs. --labels parameter and specify the key followed by an equal sign followed by the value, e.g., KEYS=VALUE
- Metadata can specify key-value pairs associated with the instance. These values are stored in a metadata server, which is available for querying using the Compute Engine API. Metadata tags are especially useful if you have a common script you want to run on startup or shutdown but want the behavior of the script to vary according to some metadata values
- Availability Policy: Preemptibility, Automatic restart, On host maintenance
- Shielded VM is an advanced set of security controls that includes Integrity Monitoring, a check to ensure boot images have not been tampered with, including Secure Boot, Virtual Trusted Platform Module, Integrity Monitoring
- Sole Tenancy is used if you need to run your VMs on physical servers that only run your VMs
- The two operations are using the book disk configuration are adding a new disk and attaching an existing disk. Reformatting an existing disk is not an option
- If you can tolerate unplanned disruptions, use preemptible VMs
- **gcloud** commands start with gcloud followed by a service, such as compute, followed by a resource type, such as instances, followed by a command or verb


Chapter 6 - Managing Virtual Machines
-------------------------------------

- The Reset in VM Connect drop down menu is to restarts a VM
- VM instance can filter by: Labels, Internal IP, External IP, Status, Zone, Network, Deletion protection, Member of managed instance group and unmanaged instance group. Multiple filter conditions, then all must be true for a VM to be listed unless you explicitly state the OR operator
- To add a GPU to an instance, you must start an instance in which GPU libraries have been installed or will be installed. Also verify that the instance will run in a zone
that has GPUs available. And CPU must be compatible with the GPU selected, and GPUs cannot be attached to shared memory machines, and must set the instance to terminate during maintenance
- When first create a snapshot, GCP will make a full copy of the data on the persistent disk. The next time create a snapshot from that disk, GCP will copy only the data that has changed since the last snapshot. This optimizes storage while keeping the snapshot up to date with the data that was on the disk the last time a snapshot operation occurred. Snapshots are copies of disks and are useful as backups and for copying data to other instances
- It is a good practice to label all resources with a consistent labeling convention
- Images are used to create VMs, can be created from the following: Disk, Snapshot, Cloud storage file, Another image. Images have an optional attribute called Family, which allows you to group images. Eventually, deprecated images will no longer be available
- Command line: --flatten, --format, --verbosity, --async, --keep-disks=all, --delete-disks=data, --filter="zone:ZONE"
- Managed groups consist of groups of identical VMs. They are created using an instance template, which is a specification of a VM configuration, including machine type, boot disk image, zone, labels, and other properties of an instance. Managed instance groups can automatically scale the number of instances in a group and be used with load balancing to distribute workloads across the instance group. If an instance in a group crashes, it will be recreated automatically. Managed groups are the preferred type of instance group
- Unmanaged groups should be used only when you need to work with different configurations within different VMs within the group
- Instance groups are sets of instances managed as a single entity. Instance groups can contain instances in a single zone or across a region. The first is called a zonal managed instance group, and the second is called a regional managed instance group. Regional managed instance groups are recommended because that configuration spreads the workload across zones, increasing resiliency
- In addition to load balancing, managed instance groups can be configured to autoscale. You can configure an autoscaling policy to trigger adding or removing instances based on CPU utilization, monitoring metric, load-balancing capacity, or queue-based workloads
- Instances are created automatically when an instance group is created


Chapter 7 - Computing with Kubernetes
-------------------------------------

- Pods treat the multiple containers as a single entity for management purposes. Replicas are copies of pods and constitute a group of pods that are managed as a unit. Pods support autoscaling as well. Pods are considered ephemeral; that is, they are expected to terminate. Pods are single instances of a running process in a cluster. Pods run containers but are not sets of containers
- Service is an object that provides API endpoints with a stable IP address that allow applications to discover pods running a particular application. Services update when changes are made to pods, so they maintain an up-to-date list of pods running an application. Services provide a level of indirection to accessing pods
- ReplicaSet is a controller used by a deployment that ensures the correct number identical of pods are running
- Deployments are sets of identical pods. The members of the set may change as some pods are terminated and others are started, but they are all running the same application
- StatefulSets are like deployments, but they assign unique identifiers to pods. This enables Kubernetes to track which pod is used by which client and keep them together. StatefulSets are used when an application needs a unique network identifier or stable persistent storage
- Job is an abstraction about a workload. Jobs create pods and run them until the application completes a workload
- The first time you use Kubernetes Engine, you may need to create credentials
- Kubernetes creates instance groups as part of the process of creating a cluster. Multizone/multiregion clusters are available in Kubernetes Engine and are used to provide resiliency to an application
- **kubectl** commands specify a verb and then a resource. **kubectl** command is used to control workloads on a Kubernetes cluster once it is created, like run a Docker image on a cluster. **kubectl**, not gcloud, is used to initiate deployments
- Stackdriver is a comprehensive monitoring, logging, alerting, and notification service that can be used to monitor Kubernetes clusters
- Workspaces are logical structures for storing information about resources in a project that are being monitored
- Alerts are assigned to instances or sets of instances


Chapter 8 - Managing Kubernetes Clusters
----------------------------------------

- **gcloud ** command is used to view, modify Kubernetes resources such as clusters, nodes (**gcloud container clusters resize**), Container Registry images (**gcloud container images list**), which managed by GCP
- **kubectl** command is used to view, modify Kubernetes resources such as pods, deployments, services, which managed by Kubernetes
- **gcloud container clusters get-credentials** command is the correct command to configure kubectl to use GCP credentials for the cluster
- **gcloud container clusters resize** command requires the name of the cluster and the node pool to modify
- Pods are used to implement replicas of a deployment. It is a best practice to modify the deployments, which are configured with a specification of the number of replicas that should always run
- Deployments are listed under Workloads in Kubernetes Engine menu
- In Create Deployment page in Cloud Console, can specify container image, cluster name, application name along with the labels, initial command, and namespace
- **kubectl run** is the command used to start a deployment. It takes a name for the deployment, an image, and a port specification
- The Container Registry is the service for managing images that can be used in other services, including Kubernetes Engine and Compute Engine
- **kubectl expose deployment** command makes a service accessible
- In Kubernetes, IP addresses are assigned to VMs, not services


Chapter 9 - Computing with App Engine
-------------------------------------

- App Engine **Standard** and App Engine **Flexible**
- App Engine **Standard** applications consist of four components: Application -> Service -> Version -> Instance
- A project can support only one App Engine app. If you’d like to run other applications, they will need to be placed in their own projects
- All resources associated with an App Engine app are created in the region specified when the app is created
- Services are defined by their source code and their configuration file. The combination of those files constitutes a version of the app
- in **app.yaml** file **runtime** parameter specifies the language environment to execute in; **script** parameter specifies the script to execute; there is no parameter for specifying the maximum time an application can run
- **gcloud app deploy app.yaml** is used to deploy an App Engine app from the command line. It breaks **gcloud [service] [resource] verb** command line convention. This command must be executed from the directory with the **app.yaml** file. **--no-promote** parameter is to deploy the app without routing traffic to it. It is the way to get code out as soon as possible without exposing it to customers
- **gcloud app logs** command
- **gcloud app browse** command
- **gcloud app versions stop** command
- App Engine applications are accessible from URLs that consist of the project name followed by appspot.com. Can also assign a custom domain rather not **appspot.com** URL. Do this from the Add New Custom domain function on the App Engine Settings page
- Two kinds of instances available in App Engine Standard - **resident instances** are resident and running all the time, optimized for performance so users will wait less while an instance is started, used with **manual scaling**; **dynamic instances** are scaled based on load, used with **autoscaling and basic scaling**
- Autoscaling enables: **target_cpu_utilization**, **target_throughput_utilization**, **max_concurrent_requests**, **max_instances**, **min_instances**, **max_pending_latency**, **min_pending_latency**
- **target_cpu_utilization** specifies the maximum CPU utilization that occurs before additional instances are started
- **target_throughput_utilization** specifies the maximum number of concurrent requests before additional instances are started, uses a 0.05 to 0.95 scale to specify maximum throughput utilization
- **max_concurrent_requests** specifies the max concurrent requests an instance can accept before starting a new instance. The default is 10; the max is 80
- **max_instances** / **min_instances** specifie the maximum / minimum number of instances that can run for this application
- **max_pending_latency** / **min_pending_latency** indicates the maximum and minimum time a request will wait in the queue to be processed
- Basic scaling only allows parameters for **idle_timeout** and **max_instances**
- Manual scaling only allows parameter for **instances**
- **IP address**, **HTTP cookie** (preferred way), and **random splitting**, are allowed methods for splitting traffic
- The cookie used for splitting in App Engine is called **GOOGAPPUID**
- **gcloud app services set-traffic** command allocates service to some users to the new version without exposing all users to it. If no service name is specified, then all services are split; **set-traffic** command takes the following parameters: **--split** is the mandatory parameter for specifying a list of instances and the percent of traffic they should receive; **--migrate** migrate traffic from the previous version to the new version; **--split-by** values are ip, cookie, and random;


Chapter 10 - Computing with Cloud Functions
-------------------------------------------

- App Engine supports multiple services organized into a single application
- Cloud Functions supports individual services that are managed and operate independently of other services. Cloud Functions will time out after 1 minute, although you can set the timeout for as long as 9 minutes
- **Events** categories: Cloud Storage, Cloud Pub/Sub, HTTP, Firebase, Stackdriver Logging
- **Trigger** is a way of responding to an event
- **Triggers** have an associated **Function**
- **Function** takes two arguments: event_data and event_context
- **Function** memory options range from 128MB to 2GB, default is 256MB
- **Function** parameters for **Cloud Storage**: Cloud function name, Memory allocated for the function, Trigger, **Event type**, Source of the function code, Runtime, Source code, Name of the function to execute
- **Function** parameters for **Cloud Pub/Sub**: Cloud function name, Memory allocated for the function, Trigger, **Topic**, Source of the function code, Runtime, Source code, Name of the function to execute
- Parameters creating Cloud Storage function: runtime, trigger-resource, trigger-event. Trigger events are: google.storage.object.finalize, google.storage.object.delete, google.storage.object.archive, google.storage.object.metadataUpdate
- Parameters creating Cloud Pub/Sub function: runtime, trigger-topic. Trigger event is: topic


Chapter 11 - Planning Storage in the Cloud
------------------------------------------

- Memorystore can be configured to use between 1GB and 300GB of memory
- Persistent disks, both SSD and HDD can be up to 64TB. Persistent disks automatically encrypt data on the disk
- Four storage classes in **Cloud Storage**: Regional, multiregional, nearline, and coldline
- Cloud Storage uses an object data model
- Lifecycle rule can be  specified on objects in Cloud Storage. Condition options: Age, Creation Data, Storage Class, Newer Versions, and Live State (live or
archived versions of an object)
- Lifecycle on Cloud Storage: Regional and multiregional class can be changed to nearline or coldline; Nearline storage class can change to coldline. Regional class storage cannot be changed to multiregional. Multiregional class cannot be changed to regional
- When versioning is enabled on a bucket, a copy of an object is archived each time the object is overwritten or when it is deleted. The most recent version of an object on bucket is called the **Live version**
- There are three broad categories of data models available in GCP: object, relational, and NoSQL. Cloud Firestore and Firebase as a fourth category
- Cloud SQL and Cloud Spanner use relational databases for transaction processing applications; BigQuery uses a relational model for data warehouse and analytic applications
- The first task for using BigQuery is to create a data set to hold data, by clicking Create Dataset
- Datastore and Firebase are document databases
- Datastore has some features in common with relational databases, such as support for transactions and indexes to improve query performance. The main difference is that Datastore does not require a fixed schema or structure and does not support relational operations, such as joining tables, or computing aggregates, such as sums and counts.
- Cloud Firestore is that it is designed for storing, synchronizing, and querying data across distributed applications, like mobile apps. Apps can be automatically updated in close to real time when data is changed on the backend. Cloud Firestore supports transactions and provides multiregional replication.
- Bigtable is a wide-column table
- Data stores decision: Read and write patterns, consistency requirements, transaction support, cost, and latency ...
- Cloud SQL and Bigtable require you to specify some configuration information for VMs
- Second-generation instance, can configure the MySQL version, connectivity, machine type, automatic backups, failover replicas, database flags, maintenance windows, and labels


Chapter 12 - Deploying Storage in Google Cloud Platform
-------------------------------------------------------

- Query the document database using GQL, a query language similar to SQL
- gcloud is used for most products but not all; gsutil is used to work with Cloud Storage from the command line; bq used for BigQuery from the command line; cbt used to work with Bigtable from the command line
- gcloud sql backups create
- gcloud sql instances patch ace-exam-mysql --backup-start-time 03:00
- gcloud datastore export –namespaces='[NAMESPACE]' gs://ace_exam_backups
- gcloud datastore import gs://[BUCKET]/[PATH]/[FILE].overall_export_metadata
- BigQuery displays an estimate of the amount of data scanned. Use the scanned data estimate with the Pricing Calculator to get an estimate cost
- In BigQuery console Job History shows active jobs, completed jobs, and jobs that generated errors
- bq ––location=[LOCATION] query ––use_legacy_sql=false ––dry_run [SQL_QUERY]
- bq --location=US show -j gcpace-project:US.bquijob_119adae7_167c373d5c3
- Subscriptions can be pulled, in which the application reads from a topic, or pushed, in which the subscription writes messages to an endpoint
- Pub/Sub will wait the period of time specified in the Acknowledgment Deadline parameter. The time to wait can range from 10 to 600 seconds
- gcloud pubsub topics create [TOPIC-NAME]
- gcloud pubsub subscriptions create [SUBSCRIPTION-NAME] ––topic [TOPIC-NAME]
- Unread messages have a retention period after which they are deleted
- cbt createtable ace-exam-bt-table
- cbt ls
- cbt createfamily ace-exam-bt-table colfam1
- cbt set ace-exam-bt-table row1 colfam1:col1=ace-exam-value
- cbt read ace-exam-bt-table
- gcloud dataproc clusters create cluster-bc3d ––zone us-west2-a
- gcloud dataproc jobs submit spark ––cluster cluster-bc3d ––jar ace_exam_jar.jar
- gsutil rewrite -s [STORAGE_CLASS] gs://[PATH_TO_OBJECT]
- gsutil mv gs://[SOURCE_BUCKET_NAME]/[SOURCE_OBJECT_NAME] gs://[DESTINATION_BUCKET_NAME]/[DESTINATION_OBJECT_NAME]
- gsutil mv gs://[BUCKET_NAME]/[OLD_OBJECT_NAME] gs://[BUCKET_NAME]/[NEW_OBJECT_NAME]


References
----------

- Official Google Cloud Certified Associate Cloud Engineer Study Guide, _https://www.wiley.com/en-au/Official+Google+Cloud+Certified+Associate+Cloud+Engineer+Study+Guide-p-9781119564393_
- QwikLabs Free Codes — GCP and AWS, _https://medium.com/@sathishvj/qwiklabs-free-codes-gcp-and-aws-e40f3855ffdb_
- GCP flowchart of decision tree, _https://medium.com/google-cloud/a-gcp-flowchart-a-day-2d57cc109401_